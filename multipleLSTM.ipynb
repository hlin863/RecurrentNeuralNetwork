{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file = '2600-0.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = open(training_file, 'r', encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the project gutenberg ebook of war and peace, by leo tolstoy\n",
      "\n",
      "this ebook is for the use of anyone anywhere in the united states and\n",
      "most other parts of the world at no cost and with almost no restric\n"
     ]
    }
   ],
   "source": [
    "print(raw_text[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nChars = len(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(raw_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nVocabs = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of vocabularies is:  83\n"
     ]
    }
   ],
   "source": [
    "print(\"The total number of vocabularies is: \", nVocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "allWords = raw_text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueWords = sorted(list(set(allWords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexToChars = dict((i, c) for i, c in enumerate(chars))\n",
    "charsToIndex = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqLength = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nSeq = int(np.floor((nChars - 1) / seqLength))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of sequences is:  20171\n"
     ]
    }
   ],
   "source": [
    "print(\"The total number of sequences is: \", nSeq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((nSeq, seqLength, nVocabs))\n",
    "y = np.zeros((nSeq, seqLength, nVocabs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nSeq):\n",
    "\n",
    "    xSequence = raw_text[i * seqLength: (i + 1) * seqLength]\n",
    "\n",
    "    xSequenceIndex = [charsToIndex[char] for char in xSequence]\n",
    "\n",
    "    inputSequence = np.zeros((seqLength, nVocabs))\n",
    "\n",
    "    for j in range(seqLength):\n",
    "\n",
    "        inputSequence[j][xSequenceIndex[j]] = 1\n",
    "\n",
    "    X[i] = inputSequence\n",
    "\n",
    "    ySequence = raw_text[i * seqLength + 1: (i + 1) * seqLength + 1]\n",
    "\n",
    "    ySequenceIndex = [charsToIndex[char] for char in ySequence]\n",
    "\n",
    "    targetSequence = np.zeros((seqLength, nVocabs))\n",
    "\n",
    "    for j in range(seqLength):\n",
    "\n",
    "        targetSequence[j][ySequenceIndex[j]] = 1\n",
    "\n",
    "    y[i] = targetSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorflow.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiddenUnits = 700\n",
    "dropOut = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 100\n",
    "nEpoch = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(hiddenUnits, input_shape=(None, nVocabs), return_sequences=True, dropout=dropOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(hiddenUnits, return_sequences=True, dropout=dropOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(nVocabs, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, None, 700)         2195200   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, None, 700)         3922800   \n",
      "                                                                 \n",
      " dense (Dense)               (None, None, 83)          58183     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,176,183\n",
      "Trainable params: 6,176,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
