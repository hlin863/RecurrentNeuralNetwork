{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file = '2600-0.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = open(training_file, 'r', encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the project gutenberg ebook of war and peace, by leo tolstoy\n",
      "\n",
      "this ebook is for the use of anyone anywhere in the united states and\n",
      "most other parts of the world at no cost and with almost no restric\n"
     ]
    }
   ],
   "source": [
    "print(raw_text[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nChars = len(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(raw_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nVocabs = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of vocabularies is:  83\n"
     ]
    }
   ],
   "source": [
    "print(\"The total number of vocabularies is: \", nVocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "allWords = raw_text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueWords = sorted(list(set(allWords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexToChars = dict((i, c) for i, c in enumerate(chars))\n",
    "charsToIndex = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqLength = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nSeq = int(np.floor((nChars - 1) / seqLength))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of sequences is:  20171\n"
     ]
    }
   ],
   "source": [
    "print(\"The total number of sequences is: \", nSeq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((nSeq, seqLength, nVocabs))\n",
    "y = np.zeros((nSeq, seqLength, nVocabs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nSeq):\n",
    "\n",
    "    xSequence = raw_text[i * seqLength: (i + 1) * seqLength]\n",
    "\n",
    "    xSequenceIndex = [charsToIndex[char] for char in xSequence]\n",
    "\n",
    "    inputSequence = np.zeros((seqLength, nVocabs))\n",
    "\n",
    "    for j in range(seqLength):\n",
    "\n",
    "        inputSequence[j][xSequenceIndex[j]] = 1\n",
    "\n",
    "    X[i] = inputSequence\n",
    "\n",
    "    ySequence = raw_text[i * seqLength + 1: (i + 1) * seqLength + 1]\n",
    "\n",
    "    ySequenceIndex = [charsToIndex[char] for char in ySequence]\n",
    "\n",
    "    targetSequence = np.zeros((seqLength, nVocabs))\n",
    "\n",
    "    for j in range(seqLength):\n",
    "\n",
    "        targetSequence[j][ySequenceIndex[j]] = 1\n",
    "\n",
    "    y[i] = targetSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorflow.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiddenUnits = 70\n",
    "dropOut = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 100\n",
    "nEpoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(hiddenUnits, input_shape=(None, nVocabs), return_sequences=True, dropout=dropOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(hiddenUnits, return_sequences=True, dropout=dropOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(nVocabs, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, None, 70)          43120     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, None, 70)          39480     \n",
      "                                                                 \n",
      " dense (Dense)               (None, None, 83)          5893      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 88,493\n",
      "Trainable params: 88,493\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback, ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = 'model.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(filePath, monitor='loss', verbose=1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStop = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateText(model, genLength, nVocab, indexToChar):\n",
    "    index = np.random.randint(nVocab)\n",
    "    yChar = [indexToChar[index]]\n",
    "    x = np.zeros((1, genLength, nVocab))\n",
    "\n",
    "    for i in range(genLength):\n",
    "        x[0, i, :][index] = 1\n",
    "        pred = model.predict(x[:, :i+1, :])[0][-1]\n",
    "        index = np.argmax(pred)\n",
    "        yChar.append(indexToChar[index])\n",
    "\n",
    "    return ''.join(yChar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultChecker(Callback):\n",
    "    def __init__(self, model, genLength, nVocab, indexToChar):\n",
    "        self.model = model\n",
    "        self.genLength = genLength\n",
    "        self.nVocab = nVocab\n",
    "        self.indexToChar = indexToChar\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        print(generateText(self.model, self.genLength, self.nVocab, self.indexToChar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultChecker = ResultChecker(model, 100, nVocabs, indexToChars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y, batch_size=batchSize, epochs=nEpoch, callbacks=[checkpoint, earlyStop, resultChecker])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
